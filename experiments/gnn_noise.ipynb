{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 15 13:28:41 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000000:CA:00.0 Off |                    0 |\r\n",
      "| N/A   38C    P0              57W / 300W |      2MiB / 81920MiB |      0%      Default |\r\n",
      "|                                         |                      |             Disabled |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "import torch.nn\n",
    "from pytorch_lightning.core.mixins import HyperparametersMixin\n",
    "from torch import Tensor as T\n",
    "from torch import nn\n",
    "from torch.nn.functional import normalize\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from torch_geometric.data import Data\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from pytorch_lightning.callbacks import Callback, TQDMProgressBar\n",
    "\n",
    "from gnn_tracking.utils.loading import TrackingDataModule\n",
    "from gnn_tracking.training.callbacks import PrintValidationMetrics\n",
    "from gnn_tracking.training.base import TrackingModule\n",
    "from gnn_tracking.models.graph_construction import GraphConstructionFCNN\n",
    "from gnn_tracking.utils.lightning import obj_from_or_to_hparams\n",
    "from gnn_tracking.models.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseModel(nn.Module, HyperparametersMixin):\n",
    "    def __init__(self, in_dim, depth, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        layers = [nn.Linear(in_dim, hidden_dim), nn.ReLU()]\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_dim, 1))  # Output layer\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseModule(TrackingModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        loss_fct: BCEWithLogitsLoss,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.loss_fct = loss_fct\n",
    "    \n",
    "    def get_losses(self, out: Any, true_hits: T) -> T:\n",
    "        return self.loss_fct(out, true_hits)\n",
    "\n",
    "    def sigmoid_and_threshold(self, logits, threshold=0.5):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        return (probs >= threshold).float()\n",
    "    \n",
    "    def get_true_hits(self, data: Data):\n",
    "        true_hits = (data.particle_id != 0) & (data.pt >= 0.5)\n",
    "        true_hits = true_hits.unsqueeze(dim=-1).type(torch.float64)\n",
    "        return true_hits\n",
    "    \n",
    "    def training_step(self, batch: Data, batch_idx: int) -> T | None:\n",
    "        out = self(batch.x)\n",
    "        true_hits = self.get_true_hits(batch)\n",
    "        loss = self.get_losses(out, true_hits)\n",
    "        \n",
    "        self.log_dict(\n",
    "            {'BCELoss_train': float(loss)},\n",
    "            prog_bar=True,\n",
    "            on_step=True,\n",
    "            batch_size=self.trainer.train_dataloader.batch_size,\n",
    "        )\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch: Data, batch_idx: int):\n",
    "        out = self(batch.x)\n",
    "        true_hits = self.get_true_hits(batch)\n",
    "        loss = self.get_losses(out, true_hits)\n",
    "        \n",
    "        self.log_dict_with_errors(\n",
    "           {'BCELoss': float(loss)}, batch_size=self.trainer.val_dataloaders.batch_size\n",
    "        )\n",
    "        \n",
    "        preds = self.sigmoid_and_threshold(out)\n",
    "        true_labels = true_hits.cpu().numpy()\n",
    "        predicted_labels = preds.cpu().numpy()\n",
    "\n",
    "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "        self.log('val_accuracy', accuracy, on_step=False, on_epoch=True)\n",
    "        self.log('val_recall', recall, on_step=False, on_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = Path(\"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_9\")\n",
    "assert val_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = []\n",
    "train_dir = Path(\"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/\")\n",
    "for i in range(1,9):\n",
    "    d = os.path.join(train_dir, f\"part_{i}\")\n",
    "    if os.path.isdir(d):\n",
    "        train_dirs.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TrackingDataModule(\n",
    "    train=dict(\n",
    "        dirs=train_dirs,\n",
    "        batch_size=1\n",
    "    ),\n",
    "    val=dict(\n",
    "        dirs=[val_dir],\n",
    "        stop=10,\n",
    "    ),\n",
    "    # could also configure a 'test' set here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[13:28:46] INFO: DataLoader will load 7743 graphs (out of 7743 available).\u001b[0m\n",
      "\u001b[36m[13:28:46] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_8/data28999_s0.pt\u001b[0m\n",
      "\u001b[32m[13:28:46] INFO: DataLoader will load 10 graphs (out of 1000 available).\u001b[0m\n",
      "\u001b[36m[13:28:46] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_9/data29009_s0.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': TrackingDataset(7743), 'val': TrackingDataset(10)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is called by the Trainer automatically and sets up the datasets\n",
    "dm.setup(stage=\"fit\")  # 'fit' combines 'train' and 'val'\n",
    "# Now the datasets are available:\n",
    "dm.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  NoiseModel(in_dim=14, depth=6, hidden_dim=256)\n",
    "nmodel = NoiseModule(\n",
    "        model=model,\n",
    "        loss_fct=BCEWithLogitsLoss(),\n",
    "        optimizer=partial(torch.optim.Adam, lr=0.001),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[32m[13:28:46] INFO: DataLoader will load 7743 graphs (out of 7743 available).\u001b[0m\n",
      "\u001b[36m[13:28:46] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_8/data28999_s0.pt\u001b[0m\n",
      "\u001b[32m[13:28:46] INFO: DataLoader will load 10 graphs (out of 1000 available).\u001b[0m\n",
      "\u001b[36m[13:28:46] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_9/data29009_s0.pt\u001b[0m\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory /home/dc3896/devdoot-gnn-tracking-experiments/experiments/lightning_logs/version_49814148/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type              | Params\n",
      "-----------------------------------------------\n",
      "0 | model    | NoiseModel        | 333 K \n",
      "1 | loss_fct | BCEWithLogitsLoss | 0     \n",
      "-----------------------------------------------\n",
      "333 K     Trainable params\n",
      "0         Non-trainable params\n",
      "333 K     Total params\n",
      "1.332     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 59357. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64895. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d8b276e7974664801263de5d1c15f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 53868. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 55699. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 57992. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 55783. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 58051. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 67990. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 61911. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/scratch/gpfs/dc3896/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 58237. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m         Validation epoch=0          \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Error\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━┩\n",
      "│ BCELoss       │ 0.66634 │ 0.00080 │\n",
      "│ BCELoss_train │ 0.67405 │     nan │\n",
      "│ val_accuracy  │ 0.58717 │     nan │\n",
      "│ val_recall    │ 0.00610 │     nan │\n",
      "└───────────────┴─────────┴─────────┘\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m         Validation epoch=1          \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Error\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━┩\n",
      "│ BCELoss       │ 0.64683 │ 0.00093 │\n",
      "│ BCELoss_train │ 0.65176 │     nan │\n",
      "│ val_accuracy  │ 0.59152 │     nan │\n",
      "│ val_recall    │ 0.10513 │     nan │\n",
      "└───────────────┴─────────┴─────────┘\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m         Validation epoch=2          \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Error\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━┩\n",
      "│ BCELoss       │ 0.64320 │ 0.00103 │\n",
      "│ BCELoss_train │ 0.63469 │     nan │\n",
      "│ val_accuracy  │ 0.58969 │     nan │\n",
      "│ val_recall    │ 0.05274 │     nan │\n",
      "└───────────────┴─────────┴─────────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m         Validation epoch=8          \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Error\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━┩\n",
      "│ BCELoss       │ 0.63778 │ 0.00098 │\n",
      "│ BCELoss_train │ 0.63003 │     nan │\n",
      "│ val_accuracy  │ 0.59346 │     nan │\n",
      "│ val_recall    │ 0.10559 │     nan │\n",
      "└───────────────┴─────────┴─────────┘\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m         Validation epoch=9          \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Error\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━┩\n",
      "│ BCELoss       │ 0.63744 │ 0.00099 │\n",
      "│ BCELoss_train │ 0.63558 │     nan │\n",
      "│ val_accuracy  │ 0.59334 │     nan │\n",
      "│ val_recall    │ 0.10821 │     nan │\n",
      "└───────────────┴─────────┴─────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "\n",
    "trainer = Trainer(max_epochs=max_epochs, accelerator=\"gpu\",\n",
    "                  log_every_n_steps=1, callbacks=[PrintValidationMetrics(),\n",
    "                                                  TQDMProgressBar(refresh_rate=5)])\n",
    "\n",
    "trainer.fit(model=nmodel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
